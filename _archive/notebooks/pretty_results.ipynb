{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model                           | Accuracy   |\n",
      "|---------------------------------|------------|\n",
      "| Llama 3.2 1B                    | 31%        |\n",
      "| Llama 3.2 3B                    | 33%        |\n",
      "| Gemma 3 1B                      | 32%        |\n",
      "| Gemma 3 4B                      | 34%        |\n",
      "| Llama 3.2 11B (never converged) | N/A        |\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "models = [\n",
    "    [\"Llama 3.2 1B\", \"31%\"],\n",
    "    [\"Llama 3.2 3B\", \"33%\"],\n",
    "    [\"Gemma 3 1B\", \"32%\"],\n",
    "    [\"Gemma 3 4B\", \"34%\"],\n",
    "    [\"Llama 3.2 11B (never converged)\", \"N/A\"]\n",
    "]\n",
    "\n",
    "table = tabulate(models, headers=[\"Model\", \"Accuracy\"], tablefmt=\"github\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">          📊 Model Accuracy Comparison          </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Model                           </span>┃<span style=\"font-weight: bold\"> Score (F1) </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\"> Llama 3.2 1B                    </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">    41%     </span>│\n",
       "│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\"> Llama 3.2 3B                    </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">    61%     </span>│\n",
       "│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\"> Gemma 3 1B                      </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">    52%     </span>│\n",
       "│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\"> Gemma 3 4B                      </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">    68%     </span>│\n",
       "│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\"> Llama 3.2 11B (never converged) </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">    </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">N/A</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">     </span>│\n",
       "└─────────────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m          📊 Model Accuracy Comparison          \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mModel                          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mScore (F1)\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│\u001b[1;37m \u001b[0m\u001b[1;37mLlama 3.2 1B                   \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m   41%    \u001b[0m\u001b[1;32m \u001b[0m│\n",
       "│\u001b[1;37m \u001b[0m\u001b[1;37mLlama 3.2 3B                   \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m   61%    \u001b[0m\u001b[1;32m \u001b[0m│\n",
       "│\u001b[1;37m \u001b[0m\u001b[1;37mGemma 3 1B                     \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m   52%    \u001b[0m\u001b[1;32m \u001b[0m│\n",
       "│\u001b[1;37m \u001b[0m\u001b[1;37mGemma 3 4B                     \u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m   68%    \u001b[0m\u001b[1;32m \u001b[0m│\n",
       "│\u001b[1;37m \u001b[0m\u001b[1;37mLlama 3.2 11B (never converged)\u001b[0m\u001b[1;37m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m   \u001b[0m\u001b[1;31mN/A\u001b[0m\u001b[1;32m    \u001b[0m\u001b[1;32m \u001b[0m│\n",
       "└─────────────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "console = Console()\n",
    "\n",
    "table = Table(title=\"📊 Model Accuracy Comparison\", title_style=\"bold cyan\")\n",
    "\n",
    "table.add_column(\"Model\", justify=\"left\", style=\"bold white\")\n",
    "table.add_column(\"Score (F1)\", justify=\"center\", style=\"bold green\")\n",
    "\n",
    "table.add_row(\"Llama 3.2 1B\", \"41%\")\n",
    "table.add_row(\"Llama 3.2 3B\", \"61%\")\n",
    "table.add_row(\"Gemma 3 1B\", \"52%\")\n",
    "table.add_row(\"Gemma 3 4B\", \"68%\")\n",
    "table.add_row(\"Llama 3.2 11B (never converged)\", \"[bold red]N/A[/bold red]\")\n",
    "\n",
    "console.print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
